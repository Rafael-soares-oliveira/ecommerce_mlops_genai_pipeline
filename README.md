# Ecommerce MLOps & GenAI Pipeline


[![Powered by Kedro](https://img.shields.io/badge/Powered_by-Kedro-ffc900?logo=Kedro)](https://kedro.org)
[![Python](https://img.shields.io/badge/Python-3.13%2B-blue?logo=Python)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-blue?logo=Docker)](https://www.docker.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Docker-green?logo=Postgresql)](https://www.postgresql.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Docker-green?logo=Ollama)](https://ollama.com/)
[![Streamlit UI](https://img.shields.io/badge/Streamlit-Docker-green?logo=Streamlit)](https://docs.streamlit.io/)

[![Ollama](https://img.shields.io/badge/theLook_eCommerce-dataset-blue?logo=GoogleCloud)](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce?project=bigquery-484420)


[![CI](https://github.com/Rafael-soares-oliveira/ecommerce_mlops_genai_pipeline/actions/workflows/ci.yml/badge.svg)](https://github.com/Rafael-soares-oliveira/ecommerce_mlops_genai_pipeline/actions/workflows/ci.yml)
![Coverage](./coverage.svg)

<br>

## 1. Objetivo do Projeto

O objetivo primÃ¡rio desta arquitetura Ã© fornecer uma plataforma analÃ­tica end-to-end altamente eficiente, projetada para operar em cenÃ¡rios de baixo recurso e com baixo/mÃ©dio volume de dados, mas com mÃ¡xima performance, robustez e precisÃ£o.

O sistema orquestra a ingestÃ£o e transformaÃ§Ã£o de arquivos Parquet em tabelas relacionais de mÃ©tricas de negÃ³cio, vetoriza metadados para busca semÃ¢ntica e disponibiliza uma interface interativa via Streamlit. AtravÃ©s de um Agente RAG (Retrieval-Augmented Generation), o usuÃ¡rio pode fazer perguntas em linguagem natural, que sÃ£o convertidas em consultas SQL validadas. A orquestraÃ§Ã£o da inteligÃªncia e a conexÃ£o com o banco de dados ocorrem de forma nativa e persistente na prÃ³pria camada de interface (Streamlit), garantindo processamento com Zero-Copy via Apache Arrow, eliminando overheads de rede e serializaÃ§Ã£o complexa.

<br>

## 2. Arquitetura do Sistema

O fluxo de dados abaixo descreve a topologia dos containers Docker e o ciclo de vida dos dados, divididos entre o processamento em Batch (ETL) e a InferÃªncia em Tempo Real (RAG e UI Interativa Unificada).

```mermaid
graph LR
    %% EstilizaÃ§Ã£o
    classDef infra fill:#2d3436,stroke:#dfe6e9,color:#fff
    classDef kedro fill:#6c5ce7,stroke:#a29bfe,color:#fff
    classDef db fill:#00b894,stroke:#55efc4,color:#fff
    classDef rag fill:#e17055,stroke:#fab1a0,color:#fff
    classDef ui fill:#d63031,stroke:#ff7675,color:#fff
    classDef viz fill:#fdcb6e,stroke:#e17055,color:#000
    classDef cron fill:#b2bec3,stroke:#636e72,color:#000

    subgraph Docker_Host ["Docker Host"]
        direction LR
        
        CRON(("â° Cron")):::cron

        subgraph UI_Container ["ğŸ’» Streamlit UI (Unificado)"]
            direction TB
            INPUT[/Pergunta do UsuÃ¡rio/]:::ui
            S_TRANS["ğŸ§  Sentence-Transformers<br/>(Cache Local)"]:::rag
            ROUTER{{"LÃ³gica RAG &<br/>Text-to-SQL"}}:::rag
            IBIS{"Ibis<br/>(Validador & Arrow)"}:::rag
            DASH["ğŸ“Š Dashboard DinÃ¢mico"]:::ui
        end

        subgraph RAG_Engine ["ğŸ§  Ollama"]
            LLM["DeepSeek-r1:1.5b"]:::rag
        end

        subgraph Postgres_Container ["ğŸ—„ï¸ PostgreSQL 18"]
            PG_ALL[("Schemas:<br/>raw_data<br/>metrics<br/>embeddings")]:::db
        end

        subgraph Kedro_Group ["âš™ï¸ Profile: ETL (EfÃªmero)"]
            K_WORKER["Kedro Worker"]:::kedro
        end

        subgraph Kedro_Viz ["ğŸ” Profile: Debug"]
            K_VIZ["Kedro Viz"]:::viz
        end
    end

    %% Fluxos ETL (Batch)
    CRON -. "Dispara" .-> K_WORKER
    K_WORKER -- "Processa e Vetoriza" --> PG_ALL
    K_WORKER -. "LÃª Metadata" .-> K_VIZ

    %% Fluxos RAG & UI (Real-time)
    INPUT --> S_TRANS
    S_TRANS -- "Busca Similaridade" --> PG_ALL
    S_TRANS --> ROUTER
    ROUTER -- "Envia Contexto e Pede SQL" --> LLM
    LLM -- "Retorna SQL" --> ROUTER
    ROUTER --> IBIS
    IBIS -- "Executa Query" --> PG_ALL
    PG_ALL -- "Retorna PyArrow" --> IBIS
    IBIS --> DASH
```


### 2.1. Detalhamento dos Componentes

#### Infraestrutura e Pipeline Batch (ETL)
* â° **Cron**: Agendador local responsÃ¡vel por disparar o script de orquestraÃ§Ã£o (`run_job.sh`) em janelas de tempo prÃ©-definidas para ingestÃ£o incremental.
* âš™ï¸ **Kedro Worker (Ibis + DuckDB)**: Container efÃªmero que encapsula a lÃ³gica de extraÃ§Ã£o e transformaÃ§Ã£o. Utiliza a engine do DuckDB via Ibis para processar os arquivos Parquet de forma vetorizada, mitigando o alto consumo de RAM. ApÃ³s a execuÃ§Ã£o, o container Ã© encerrado, liberando recursos do Host.
* ğŸ§  **Sentence-Transfomers**: Etapa do pipeline responsÃ¡vel por ler o dicionÃ¡rio de dados e metadados estruturados, convertendo-os em representaÃ§Ãµes vetoriais (embeddings) para carga no banco.
* ğŸ” **Kedro Viz**: ServiÃ§o de documentaÃ§Ã£o visual sob demanda. LÃª os metadados gerados pelo Kedro Worker para exibir o grafo de dependÃªncias e a linhagem dos dados (*Data Lineage*). SÃ³ consome recursos quanto ativado manualmente.

#### Camada de PersistÃªncia
* ğŸ—„ï¸ **PostgreSQL 18 (Tuned)**: Banco de dados relacional e vetorial tunado para alta performance analÃ­tica. Segmentado logicamente em schema (`raw_data`, `metrics`, `embeddings`), utiliza a extensÃ£o `pgvector` para buscas semÃ¢nticas.

#### Motor RAG e InferÃªncia (Tempo Real)
* ğŸ’» **Streamlit UI (Motor Unificado)**: Ponto central de contato e orquestraÃ§Ã£o.
	* **Interface e Dashboard**: Captura a pergunta em linguagem natural e renderiza os DataFrames e grÃ¡ficos dinÃ¢micos.
	* **Sentence-Transformers (Real-time)**: Gera o *embedding* da pergunta do usuÃ¡rio localmente (via CPU) para consulta ao banco.
	* **Roteador & Text-to-SQL**: LÃ³gica embutida no backend do Streamlit que envia o contexto (esquema do banco recuperado) para o motor SLM e recebe a consulta SQL estruturada.
	* **Ibis (Executor e Validador)**: MantÃ©m uma conexÃ£o persistente (via `@st.cache_resource`) com o PostgreSQL. Executa o SQL gerado pelo RAG, valida a sintaxe e retorna os dados nativamente no formato **Apache Arrow**, evitando custos de conversÃ£o JSON.
* ğŸ§  **Ollama (Motor de InferÃªncia SLM)**: ServiÃ§o isolado que hospeda o modelo na GPU. Atua estritamente como um gerador de texto a partir dos prompts estruturados enviados pelo Streamlit.


<br>

## 3. Escolhas TecnolÃ³gicas e Justificativas Arquiteturais

A stack foi selecionada sob a premissa de **"foco absoluto em eficiÃªncia, baixo volume de dados e otimizaÃ§Ã£o de VRAM/RAM"**.
* **Arquitetura Unificada (Streamlit + Ibis)**: A decisÃ£o de remover uma camada intermediÃ¡ria de API (como FastAPI/gRPC) e rodar o Ibis diretamente no processo persistente do Streamlit reduz o footprint de memÃ³ria e elimina a latÃªncia de rede interna. O transporte de dados via PyArrow entre o banco e a interface ocorre com eficiÃªncia mÃ¡xima (_Zero-Copy_).
- **Ollama (`OLLAMA_KEEP_ALIVE=5m`)**: Para proteger uma limitada VRAM e evitar travamentos no sistema operacional do Host, o Ollama foi configurado para descarregar o modelo SLM da memÃ³ria da placa de vÃ­deo apÃ³s apenas 5 minutos de inatividade (_idle_). O modelo sÃ³ ocupa VRAM quando ativamente consultado.
- **LimitaÃ§Ã£o de Recursos no Docker (Deploy Limits)**: Cada serviÃ§o no `docker-compose.yml` possui limites rÃ­gidos de RAM. Isso garante que o sistema do Host tenha fÃ´lego de sobra para o SO e operaÃ§Ãµes de disco, prevenindo _Out of Memory (OOM) kills_.
- **PostgreSQL 18 Tunado (Timescale + pgvector)**: A imagem Docker base foi customizada.
    - A memÃ³ria `maintenance_work_mem` foi ajustada para suportar a criaÃ§Ã£o de Ã­ndices HNSW sem estourar a memÃ³ria do container.
    - O `jit` foi desabilitado, pois em consultas vetorizadas rÃ¡pidas (tÃ­picas de RAG), a compilaÃ§Ã£o _Just-in-Time_ adiciona latÃªncia desnecessÃ¡ria.
- **Kedro Worker EfÃªmero e Profiles Docker**: Ferramentas de engenharia e observabilidade (Kedro e Kedro-Viz) nÃ£o rodam continuamente. O uso de `profiles` no Docker Compose assegura que esses containers sÃ³ consumam RAM e CPU durante as janelas de processamento batch (ETL) ou depuraÃ§Ã£o.
- **Cache de Modelos no Docker Build (UV)**: O `Dockerfile.app` utiliza o gerenciador de pacotes `uv` e a montagem de cache (`--mount=type=cache`) para baixar o modelo `Sentence-Transformer` durante o _build_. Isso isola o ambiente e garante inicializaÃ§Ãµes instantÃ¢neas.

<br>

## 4. Pipeline de Dados: Passo a Passo e DecisÃµes de Engenharia

O projeto Ã© dividido em dois ciclos operacionais distintos: o processamento em Batch (ETL) e a inferÃªncia em tempo real.

### Fase 1: IngestÃ£o e PreparaÃ§Ã£o Batch (ExecuÃ§Ã£o EfÃªmera)

1. **ExtraÃ§Ã£o e TransformaÃ§Ã£o Ibis/DuckDB**: O Kedro executa transformaÃ§Ãµes usando o Ibis, que delega o processamento para o DuckDB. Isso garante velocidade vetorizada na leitura dos arquivos de origem (Parquet) sem consumir RAM excessiva, substituindo as operaÃ§Ãµes custosas do Pandas.
2. **Carga no PostgreSQL via Custom Dataset (Ibis Upsert)**: O Kedro nÃ£o possui um conector robusto para realizar operaÃ§Ãµes de UPSERT nativas via Ibis no PostgreSQL. O desenvolvimento de um Custom Dataset garante que os dados em `raw_data` e as mÃ©tricas geradas sejam inseridos de forma **idempotente**. ExecuÃ§Ãµes repetidas do `run_job.sh` nÃ£o duplicarÃ£o os registros.
3. **VetorizaÃ§Ã£o (Sentence-Transformers)**: ApÃ³s a criaÃ§Ã£o das mÃ©tricas, os metadados (esquemas, descriÃ§Ãµes, dicionÃ¡rios de dados) sÃ£o passados pelo cache do modelo local (configurado no `.env` via `HF_HOME`) e salvos no schema `embeddings` via `pgvector`.

### Fase 2: Motor AnalÃ­tico RAG (Tempo Real via API e UI)

1. **Input do UsuÃ¡rio**: O usuÃ¡rio envia uma pergunta na interface do Streamlit.
2. **VetorizaÃ§Ã£o Local**: O prÃ³prio backend persistente do Streamlit gera o _embedding_ da pergunta usando CPU.
3. **Busca SemÃ¢ntica (Hybrid Search)**: O Streamlit, atravÃ©s de sua conexÃ£o persistente do Ibis, aciona o banco para realizar uma busca nos `embeddings`, utilizando recursos avanÃ§ados (como `pg_trgm` ou Ã­ndices dedicados), recuperando as tabelas e colunas com maior relevÃ¢ncia.
4. **Prompt Roteador (Text-to-SQL)**: O contexto recuperado Ã© formatado e enviado ao serviÃ§o do Ollama, que atua apenas como motor de inferÃªncia, retornando a query SQL gerada.
5. **Loop de ValidaÃ§Ã£o AutomÃ¡tica**: O Streamlit tenta compilar a query recebida via Ibis. Se ocorrer erro de sintaxe ou mapeamento incorreto (ex: coluna alucinada pelo SLM), o erro Ã© capturado pela aplicaÃ§Ã£o e enviado de volta ao Ollama para correÃ§Ã£o (Self-Correction), protegendo a interface de quebras.
6. **Entrega e VisualizaÃ§Ã£o**: Com a query validada, o Ibis executa a consulta no PostgreSQL. Os resultados trafegam de volta para o Streamlit em formato binÃ¡rio **PyArrow**, garantindo mÃ¡xima velocidade de carregamento para a renderizaÃ§Ã£o do Dashboard.

<br>

## 5. Engenharia de Dados: OrquestraÃ§Ã£o e PadrÃµes com Kedro

A camada de preparaÃ§Ã£o de dados foi arquitetada sobre o framework **Kedro**, operando de forma efÃªmera e contÃªinerizada. Para garantir que o pipeline respeite as premissas de baixo consumo de recursos e alta performance, o comportamento padrÃ£o do Kedro foi estendido atravÃ©s de Hooks customizados e Custom Dataset do Kedro-datasets.

### 5.1. Observabilidade e Monitoramento de Recursos (Hooks e Logging)

Em ambientes contÃªinerizados com limites estritos de memÃ³ria, vazamentos (*memory leaks*) na etapa de ETL podem derrubar o *Docker Host*. Para mitigar isso, implementamos:
* **Logging Estruturado (`logging.yml`)**: SeparaÃ§Ã£o clara entre logs informativos e de erro, com rotatividade automÃ¡tica (`RotatingFileHandler` com backup limitado). Evita o inchaÃ§o do armazenamento local.
* **`ResourceMonitoringHook`**: Um hook injetado no ciclo de vida do Kedro que atua como um inspetor de recursos.
	* Utiliza a biblioteca `psutil` para capturar a memÃ³ria RAM exata (*RSS*) antes e depois da execuÃ§Ã£o de cada *Node*.
	* Mede o delta de memÃ³ria e o tempo de execuÃ§Ã£o (em segundos).
	* Dispara *flags* de alerta (`HIGH MEMORY`) no log caso um nÃ³ ultrapasse o limite seguro estipulado no `parameters.yml`. Isso permite identificar imediatamente transformaÃ§Ãµes nÃ£o-otimizadas.

### 5.2. OtimizaÃ§Ã£o de Banco de Dados via Ciclo de Vida `CreateIndexesHook`

A manipulaÃ§Ã£o de dados em massa (Bulk Load) em tabelas que possuem Ã­ndices complexos â€” especialmente os Ã­ndices vetoriais `HNSW` do *pgvector* â€” sofre de grave degradaÃ§Ã£o de performance.
Para resolver isso, o `CreateIndexesHook` altera o fluxo padrÃ£o de DDL (Data Definition Language):
1. `before_pipeline_run`: Conecta ao PostgreSQL e executa os scripts DDL iniciais para garantir que as tabelas do schema `raw_data` existam (sem Ã­ndices).
2. `after_pipeline_run`: Apenas apÃ³s toda a carga de dados ser finalizada, o hook executa a criaÃ§Ã£o dos Ã­ndices (B-Tree para mÃ©tricas e HNSW para vetores). Criar Ã­ndices sobre tabelas jÃ¡ populadas Ã© mais rÃ¡pido e eficiente do que atualizar o Ã­ndice linha a linha durante o *Insert*.

### 5.3. IngestÃ£o de Alta Performance `IbisUpsertDataset`

O gargalo de qualquer pipeline ETL moderno Ã© a etapa de escrita no banco de dados. O Kedro nativo nÃ£o oferece suporte eficiente para operaÃ§Ãµes idempotentes de `UPSERT` usando Ibis. A classe `IbisUpsertDataset` foi criada combinando o padrÃ£o *Factory* com serializaÃ§Ã£o em baixo nÃ­vel.
Como funciona:
1. **Zero-Copy e Arrow**: Os dados transformados pelo DuckDB sÃ£o mantidos em `PyArrow`.
2. **Protocolo BinÃ¡rio (`pgpq`)**: O dataset utiliza a biblioteca `pgpq` para codificar os dados do Arrow diretamente para o formato binÃ¡rio nativo do PostgreSQL, evitando a geraÃ§Ã£o custosa de strings `INSERT INTO`.
3. **Carga em MemÃ³ria (COPY)**: Usa a instruÃ§Ã£o `COPY FROM STDIN WITH (FORMAT BINARY)` para carregar os dados em uma tabela temporÃ¡ria quase instantaneamente.
4. **Merge Inteligente (Upsert)**: Compara a tabela temporÃ¡ria com a tabela final, gerando dinamicamente um `ON CONFLICT DO UPDATE` que sÃ³ sobrescreve o dado se houver diferenÃ§a real (`IS DISTINCT FROM`). Isso reduz o I/O de disco e o inchaÃ§o do *Write-Ahead Log* (WAL).

### 5.4. CatÃ¡logo DinÃ¢mico e DRY `catalog.yml`

O CatÃ¡logo de Dados foi desenhado seguindo o princÃ­pio *DRY* (*Don't Repeat Yourself*).
* **PadrÃµes DinÃ¢micos (`{table}`)**: A sintaxe de fÃ¡brica (ex:`raw_{table}`) mapeia automaticamente qualquer arquivo `.parquet` na camada `01_raw` atravÃ©s da engine do DuckDB, eliminando mapeamentos manuais extensivos.
* **YAML Anchors**: ConfiguraÃ§Ãµes repetitivas (credenciais, uso da classe `IbisUpsertDataset`) sÃ£o encapsuladas no *anchor* `&postgres_upsert_base`. Adicionar uma nova entidade exige apenas referenciar a base e definir o `table_name`.

### 5.5. Pipeline de Processamento e Qualidade de Dados (`data_processing`)

O pipeline de extraÃ§Ã£o e transformaÃ§Ã£o (`data_processing`) atua como a barreira de qualidade. Utiliza o **Ibis** para delegar a computaÃ§Ã£o pesada ao DuckDB e ao PostgreSQL de forma vetorizada.

### A. ValidaÃ§Ã£o de Qualidade em Passagem Ãšnica (Single-Pass Validation)

* `schema_rules.py`: Define contratos estritos de dados (regras de linha e estruturais).
* `_validate_ibis_table`: Em vez de loops de validaÃ§Ã£o custosos, compila todas as regras em um **Ãºnico bloco de agregaÃ§Ãµes Ibis**. Executa a query no banco/engine, abortando o pipeline com um `ValueError` detalhando caso qualquer regra retorne uma violaÃ§Ã£o (`> 0`). Garante a polÃ­tica "Lixo nÃ£o entra".

#### B. ProteÃ§Ã£o de Integridade Referencial DinÃ¢mica (Cross-Engine Joins)

Para evitar quebras de pipeline por erros de chave estrangeira (FK), durante o `INSERT`:
1. IDs validados do PostgreSQL sÃ£o convertidos em `PyArrow` e carregados como `ibis.memtable` (tabela virtual em memÃ³ria).
2. Realiza-se um Cross-Engine Join entre a origem (DuckDB/Parquet) e as FKs validadas:
	* **Anti-Join**: Identifica e registra nos logs (como *warnings*) os registros Ã³rfÃ£os.
	* **Semi-Join**: Filtra a base original, enviando para o Upsert apenas as linhas com correspondÃªncia vÃ¡lida no banco destino.

#### C. EstratÃ©gias de Carga Incremental

Para manter a carga leve:
* **Watermarking**: Tabelas de log (ex: `inventory_items`)consultam o destino para a data mÃ¡xima inserida (`max(created_at)`), processando apenas registros novos.
* **Moving Window**: Tabelas transacionais mutÃ¡veis (`orders` e `order_items`), usam um `lookback` configurÃ¡vel em dias, atualizando apenas pedidos recentes e ignorando histÃ³ricos estÃ¡ticos.

#### D. Imutabilidade e ConsistÃªncia Funcional

A lÃ³gica de transformaÃ§Ã£o de negÃ³cio em `transform_tables.py` segue programaÃ§Ã£o funcional (recebe `ibis.Table`, retorna `ibis.Table`).
Para injetar as validaÃ§Ãµes sem poluir a execuÃ§Ã£o do Kedro, o utilitÃ¡rio `create_node_func` (`functools.partial`) aplica os contratos de esquema de forma transparente, garantindo que a observabilidade no `kedro-viz` e nos logs reflita as operaÃ§Ãµes reais.


## Tech Stack

- **Gerenciamento**: `uv` (Astral)
- **OrquestraÃ§Ã£o**: Kedro + Kedro-Viz
- **Processamento**: Ibis + PyArrow
- **Qualidade de CÃ³digo**: Ruff (Lint), Ty (Typing), Pytest (Testes)
- **Banco de Dados**: PostgreSQL + pgvector + postGIS + TimescaleDB (via Docker), DuckDB
- **Modelos AI**:
  - *Embedding*: `all_MiniLM-L6-v2` (local)
  - *SLM*: `deepseek-r1:1.5b` (via Ollama) (local)

## Estrutura do RepositÃ³rio

``` plaintext
.
â”œâ”€â”€ conf # ConfiguraÃ§Ãµes do Kedro
â”‚   â”œâ”€â”€ base/                     # ConfiguraÃ§Ãµes padrÃ£o e compartilhadas
â”‚   â”‚   â”œâ”€â”€ catalog.yml           # Data Catalog
â”‚   â”‚   â”œâ”€â”€ globals.yml           # ParÃ¢metros compartilhados entre YML
â”‚   â”‚   â””â”€â”€ parameters.yml        # ParÃ¢metros dos pipelines
â”‚
â”‚   â”œâ”€â”€ local/                    # SobrescriÃ§Ãµes locais e credenciais (ignorado no git)
â”‚   â”œâ”€â”€ logging.yml               # ConfiguraÃ§Ã£o do Logger
â”‚   â””â”€â”€ README.md                 # DocumentaÃ§Ã£o dos arquivos de configuraÃ§Ã£o
â”‚
â”œâ”€â”€ data/                         # Armazenamento local particionado pelas camadas do Kedro
â”‚   â”œâ”€â”€ 01_raw/                   # Dados brutos e imutÃ¡veis
â”‚   â”œâ”€â”€ 02_intermediate/          # Dados limpos e tipados
â”‚   â”œâ”€â”€ 03_primary/               # Dados padronizados para o modelo de domÃ­nio
â”‚   â”œâ”€â”€ 04_feature/               # Features de machine learning
â”‚   â”œâ”€â”€ 05_model_input/           # Matrizes e tensores para treinamento
â”‚   â”œâ”€â”€ 06_models/                # Modelos serializados
â”‚   â”œâ”€â”€ 07_model_output/          # InferÃªncias e prediÃ§Ãµes
â”‚   â””â”€â”€ 08_reporting/             # Dados agregados para visualizaÃ§Ã£o
â”‚
â”œâ”€â”€ junit/                        # RelatÃ³rios de testes exportados pelo Pytest/GitHub Actions
â”œâ”€â”€ logs/                         # Arquivos de log locais
â”œâ”€â”€ notebooks/                    # Rascunhos e experimentaÃ§Ãµes (ignora no git)
â”œâ”€â”€ pyproject.toml                # ConfiguraÃ§Ãµes do projeto e ferramentas
â”œâ”€â”€ README.md                     # Este arquivo
â”œâ”€â”€ sql/                          # Scripts e queries SQL
â”‚   â”œâ”€â”€ embeddings/               # Scripts para criaÃ§Ã£o e indexaÃ§Ã£o de tabelas de vetores
â”‚   â”œâ”€â”€ init.sql                  # Script de inicializaÃ§Ã£o do banco de dados (junto com o Docker)
â”‚   â”œâ”€â”€ metrics/                  # Scripts para criaÃ§Ã£o e indexaÃ§Ã£o de tabela de mÃ©tricas
â”‚   â””â”€â”€ raw_data/                 # Scripts para criaÃ§Ã£o e indexaÃ§Ã£o de tabelas pÃ³s-tratamento
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ thelook_ecommerce_analysis/
â”‚       â”œâ”€â”€ datasets/             # ImplementaÃ§Ã£o de datasets customizados
â”‚       â”œâ”€â”€ hooks.py              # Hooks de execuÃ§Ã£o do Kedro
â”‚       â”œâ”€â”€ pipeline_registry.py  # Registro central dos pipelines disponÃ­veis
â”‚       â”œâ”€â”€ settings.py           # ConfiguraÃ§Ãµes globais de execuÃ§Ã£o do Kedro
â”‚       â”œâ”€â”€ utils/                # FunÃ§Ãµes utilitÃ¡rias
â”‚       â””â”€â”€ pipelines             # Pipelines de dados
â”‚           â””â”€â”€ data_processing   # ExtraÃ§Ã£o, transformaÃ§Ã£o e carga inicial
â”‚
â”œâ”€â”€ tests/                        # Testes unitÃ¡rios espelhando a estrutura do src/
â”‚   â”œâ”€â”€ datasets/                 # Testes dos custom datasets
â”‚   â”œâ”€â”€ kedro_settings            # Testes das configuraÃ§Ãµes do Kedro
â”‚   â”œâ”€â”€ pipelines                 # Testes das lÃ³gicas dos pipelines e nodes
â”‚   â””â”€â”€ utils                     # Teste das funÃ§Ãµes utilitÃ¡rias
â”‚
â”œâ”€â”€ docker-compose.yml            # DefiniÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ Dockerfile                    # Imagem do banco de dados PostgreSQL
â”œâ”€â”€ Dockerfile.app                # Imagem da aplicaÃ§Ã£o Kedro
â”œâ”€â”€ start.sh                      # Script para iniciar serviÃ§os de infra
â”œâ”€â”€ run_job.sh                    # Instancia o container efÃªmero do Kedro para execuÃ§Ã£o
â”œâ”€â”€ down.sh                       # Encerra serviÃ§os e limpa volumes
â””â”€â”€ uv.lock                       # Lockfile de dependÃªncias gerenciado pelo UV
```

## Como Executar

### PrÃ©-requisitos

- [Docker Engine](https://docs.docker.com/engine/install) (Pode ser configurado para [Podman](https://podman.io/docs/installation))
- GPU Nvidia (mudar configuraÃ§Ã£o para outras GPUs) / CPU tambÃ©m disponÃ­vel, porÃ©m mais lento

1. **Clone o repositÃ³rio**:

```
git clone https://github.com/Rafael-soares-oliveira/ecommerce_mlops_genai_pipeline
cd ecommerce_mlops_genai_pipeline
```

2. **Configure o ambiente**: Crie uma cÃ³pia do arquivo de variÃ¡veis de ambiente.
```
cp .env.example .env
```

3. **Inicie a infraestrutura base**: Este script levanta o banco de dados e o servidor Ollama, detectando automaticamente o uso de GPU.
```
bash start.sh
```

4. **Execute o pipeline de dados (ETL)**: Dispara o container efÃªmero do Kedro para ingestÃ£o, transformaÃ§Ã£o e geraÃ§Ã£o de embeddings.
```
bash run_job.sh
```

5. **Acesse as interfaces**:
* **Streamlit (UI)**: `http://localhost:8501`
* **Kedro-Viz (Lineage)**: `http://localhost:4141`
* **pgAdmin**: `http://localhost:8080`

## Tabelas de MÃ©tricas

- **MÃ©tricas de Vendas e Receita**: Focada no desempenho financeiro.
  - **Tabelas Fonte**: `order_items`, `orders`, `products`.
  - **MÃ©tricas**:
    - **GMV (Gross Merchandise Value)**: Soma total do valor das vendas (`sale_price`).
    - **Ticket MÃ©dio (AOV)**: MÃ©dia de gasto por pedido.
    - **Taxa de Cancelamento**: % de pedidos com status `Cancelled`.
- **MÃ©tricas de Clientes (CRM e RetenÃ§Ã£o)**: Focada no comportamento e valor do usuÃ¡rio ao longo do tempo.
  - **Tabelas Fonte**: `users`, `orders`.
  - **MÃ©tricas**:
    - **LTV (Lifetime Value)**: Valor total gasto por usuÃ¡rio desde o cadastro.
    - **AnÃ¡lise de Cohort**: RetenÃ§Ã£o de usuÃ¡rio agrupados pelo mÃªs de aquisiÃ§Ã£o (safra).
    - **RFM (RecÃªncia, FrequÃªncia, MonetÃ¡rio)**: SegmentaÃ§Ã£o de clientes para marketing.
    - **Novos vs. Recorrentes**: ProporÃ§Ã£o de vendas de primeira compra vs. recompra.
- **MÃ©tricas de Produto e Estoque**: Focada na logÃ­stica e atratividade do item.
  - **Tabelas Fonte**: `inventory_items`, `products`, `order_items`, `distribution_center`.
  - **MÃ©tricas**:
    - **Taxa de DevoluÃ§Ã£o**: % de itens com status `Returned`.
    - **Tempo de Envio**: DiferenÃ§a entre `created_at` e `shipped_at`.
    - **Margem de Produto**: DiferenÃ§a entre `sale_price` e `cost`.
    - **Aging do Estoque**: Tempo que os itens ficam no inventÃ¡rio antes da venda.
- **MÃ©tricas de NavegaÃ§Ã£o (Web Analytics)**: Focada no funil de conversÃ£o no site.
  - **Tabelas Fonte**: `events`.
  - **MÃ©tricas PossÃ­veis**:
    - **Taxa de ConversÃ£o de SessÃ£o**: Visitantes Ãºnicos que compram / Total de visitantes.
    - **Abandono de Carrinho**: UsuÃ¡rios que adicionam ao carrinho (`cart`) mas nÃ£o compram (`purchase`).
    - **Origem de TrÃ¡fego**: AnÃ¡lise da coluna `traffic_source`.

## Roadmap de ImplementaÃ§Ã£o (Planejamento)

Este planejamento foca nas entregas lÃ³gicas, sem datas fixas.

### Fase 1: FundaÃ§Ã£o & Infraestrutura

- [X] Configurar repositÃ³rio com `.gitignore` e `pyproject.toml`.
- [X] Criar `docker-compose.yml`, `Dockerfile` e scripts `sh`.
- [X] Configurar/Validar conexÃ£o com o Banco de Dados.

### Fase 2: Core Engineering (Kedro ETL)

- [X] Inicializar projeto Kedro (`kedro new`).
- [X] Configurar `crendentials.yml` e `parameters.yml`.
- [X] Configurar `conf/base/logging.yml` e configurar Hooks do Kedro.
- [X] Criar testes unitÃ¡rios para testar hooks.py e settings.py
- [X] Registrar datasets no `catalog.yml`.
- [X] Implementar **Pipeline de TransformaÃ§Ã£o**:
  - [X] Limpeza com Ibis.
  - [X] LÃ³gica de Watermark (Upsert) lendo do Postgres.
- [X] Criar testes com pelo menos 90% coverage
- [X] Configurar pipeline de CI (GitHub Actions) para rodar `ruff`, `ty`, `pytest` e gerar relatÃ³rios.
- [X] Documentar no README.md

### Fase 3: MÃ©tricas, Vetores e AI

- [ ] Implementar **Pipeline de Embeddings**:
  - [ ] Node para gerar vetores de descriÃ§Ãµes de produtos.
  - [ ] Criar testes com pelo menos 90% coverage
  - [ ] Documentar no README.md
- [ ] Implementar **Pipeline de MÃ©tricas**:
  - [ ] Node para criar tabelas de mÃ©tricas
  - [ ] Criar testes com pelo menos 90% coverage
  - [ ] Documentar no README.md
- [ ] Implementar **Pipeline de SLM Batch**:
  - [ ] Configurar modelo e contexto
  - [ ] Node que agrega mÃ©tricas diÃ¡rias.
  - [ ] IntegraÃ§Ã£o com API do Ollama para gerar resumos textuais.

### Fase 4: Consumo e VisualizaÃ§Ã£o

- [ ] Configurar API REST.
- [ ] Configurar Streamlit.
- [ ] Cria dashboard modelo no Streamlit.
- [ ] Criar Dashboard no Streamlit.
- [ ] Implementar Chatbot RAG no Streamlit.
